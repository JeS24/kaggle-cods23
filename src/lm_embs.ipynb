{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMs for keyphrase extraction (using the `KeyBERT` library)\n",
    "* ‚ùå - Bad performance | ‚úÖ - Good performance (* - best performance) | üö´ - Not usable\n",
    "* `vasugoel/K-12BERT` - [Indian corpus](https://medium.com/@vasu18322/k-12bert-bert-for-k-12-education-96a8a6ee9265)\n",
    "* For `openaccess-ai-collective/jackalope-7b`:\n",
    "    `kw_model.model.embedding_model.tokenizer.pad_token = kw_model.model.embedding_model.tokenizer.eos_token`\n",
    "\n",
    "| Model                                                | Status |\n",
    "|--------------------------------------------------    |:---:|\n",
    "| `google/flan-t5-large`                               | ‚ùå |\n",
    "| `dbmdz/bert-large-cased-finetuned-conll03-english`   | ‚ùå |\n",
    "| `yanekyuk/bert-uncased-keyword-extractor`            | ‚ùå |\n",
    "| `allenai/scibert_scivocab_uncased`                   | ‚úÖ |\n",
    "| `vasugoel/K-12BERT`                                  | ‚úÖ* | \n",
    "| `ogimgio/K-12BERT-reward-neurallinguisticpioneers-3` | ‚úÖ* |\n",
    "| `bbunzeck/gpt-wee-curriculum`                        | ‚úÖ |\n",
    "| `openaccess-ai-collective/jackalope-7b`              | ‚úÖ |\n",
    "| `Nonegom/roberta_curriculum_learn`                   | ‚úÖ |\n",
    "| `egumasa/roberta-base-academic`                      | ‚úÖ |\n",
    "| `spacy/en_core_web_lg`                               | üö´ |\n",
    "| `51la5/roberta-large-NER`                            | üö´ |\n",
    "| `EhimeNLP/AcademicBART`                              | üö´ |\n",
    "| `brennan-richards/gpt2-finetuned-academic-topics`    | üö´ |\n",
    "| `crumb/44m-textbook`                                 | üö´ |\n",
    "| `openaccess-ai-collective/mistral-100m-textbooks`    | üö´ |\n",
    "| `Taekyoon/textbook_scramble`                         | üö´ |\n",
    "| `jupiterben/gpt-academic`                            | üö´ |\n",
    "| `Dongchao/AcademiCodec`                              | üö´ |\n",
    "| `ricardo-filho/BERT-pt-institutional-corpus-v.1`     | ‚ùå | \n",
    "\n",
    "### LMs for grammar checking & prepping for keyphrase extraction\n",
    "| Model                                                | Status |\n",
    "|--------------------------------------------------    |:---:|\n",
    "| `grammarly/coedit-large`                             | ‚ùå |\n",
    "| `grammarly/coedit-xl-composite`                      | ‚úÖ |\n",
    "| `vennify/t5-base-grammar-correction`                 | ‚ùå |\n",
    "| `pszemraj/flan-t5-large-grammar-synthesis`           | ‚ùå |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep text\n",
    "- [x] Grammar correction\n",
    "    - [x] Remove numbers\n",
    "    - [x] Remove / augment non-words\n",
    "- [x] Other NLP prep:\n",
    "    - [x] Remove stopwords\n",
    "    - [x] Remove punctuation\n",
    "    - [x] Stemming - ‚ùå\n",
    "    - [x] Lemmatization - ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking transcripts\n",
    "NOTE:\n",
    "* Transcripts don't have numbers in them.\n",
    "* There are contractions in the transcripts, like \"don't\".\n",
    "* There are many grammatical, spelling & syntactical errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "ROOT = \"../data/kagdata/\"\n",
    "TO = ROOT + \"cleaned/\"\n",
    "\n",
    "meta = pd.read_csv(ROOT + \"metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Collection and Presentation of Data - I', 'Dalton√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢s Atomic Theory', \"kepler's first law\", 'Average Speed', 'Linear Graph', 'Angles', 'Congruent Figures', 'Climatic Adaptations in Animals of Tropical Rainforests', 'Climatic Adaptations in Animals of Polar Regions', 'Plane Mirror and Image Formation', 'Types of Angles', 'Conservation of Water', 'Importance of Water', 'Potential Energy', 'Demagnetizing a Magnet', 'Regeneration', 'Sexual Reproduction in Plants', 'Converse of BPT', 'Similar Polygons', 'Discovery of Subatomic Particles', 'Thomson Atomic Model', 'Thomson√É¬¢√¢‚Äö¬¨√¢‚Äû¬¢s Plum Pudding Model', 'Thrust and Pressure', 'Care of Eyes', 'Image Formation by a Plane Mirror', 'Compound Interest', 'Convex and Concave Polygons', 'Profit and Loss', 'Fibre to Wool', 'Formation of water table', 'Irrigation', 'Minerals', 'Magnetic Field and Terrestrial Magnetism', 'Verification of Pythagoras Theorem', \"Boyle's Law\", \"Henry's Law\", 'Phagocytosis in Amoeba', '5R s of Management', 'Addition and Subtraction of Integers', 'Raoults law', 'Scattering of Light', 'The Principle of Electromagnetic Induction', \"Thomson's Plum Pudding Model\", 'Lightning and Lightning Conductors', 'Structure of Nephron', 'Charge particle in magnetic field', 'Intoduction to Potential Energy', 'Introduction to Rational Numbers', 'Distance and Displacement', 'Introduction to Human Musculo - Skeletal System']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "RE_D = re.compile('\\d')\n",
    "titles = []\n",
    "for title, trans in meta[['video name', 'transcript']].values:\n",
    "    # If there is a number in the transcript, print title\n",
    "    res = RE_D.search(trans)\n",
    "    if res:\n",
    "        print(title)\n",
    "    # trans = '' + trans\n",
    "    if not trans.strip().replace(' ', '').isalpha():\n",
    "        titles.append(title)\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct grammar + Preprocess + Generate keyphrases / embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/js/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/js/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/js/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For grammatical corrections\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"grammarly/coedit-xl-composite\")\n",
    "grammar_model = T5ForConditionalGeneration.from_pretrained(\"grammarly/coedit-xl-composite\")\n",
    "grammar_model.to('cuda');\n",
    "\n",
    "# For text preprocessing (before embedding generation)\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# For embedding generation\n",
    "from keybert import KeyBERT\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "kw_model = KeyBERT(model=TransformerDocumentEmbeddings('ogimgio/K-12BERT-reward-neurallinguisticpioneers-3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses text by converting to lowercase, removing punctuation & \n",
    "    special characters, stop words, and lemmatizing.\n",
    "\n",
    "    \"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    # Lemmatizate\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    lemmatized_text = ' '.join(lemmatized_words)\n",
    "\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "pe = pd.read_csv(\"../data/kagdata/pre_embeddings_std_combined.csv\", converters={'pre_embed_vec': literal_eval})\n",
    "# Add columns in pe for doc_emb_unproc & doc_emb\n",
    "pe['doc_emb_unproc'] = np.nan\n",
    "pe['doc_emb'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings for work: : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1092/1092 [9:09:37<00:00, 30.20s/it]                                                                      \n"
     ]
    }
   ],
   "source": [
    "itr = tqdm(pe['title'].values)\n",
    "for ttl in itr:\n",
    "    # CONCERN: Set to 0s ?\n",
    "    if ttl in [\"3D circulatory system\", \"Introduction to Human Musculo - Skeletal System\"]:\n",
    "        continue\n",
    "\n",
    "    text = meta[meta['video name'] == ttl]['transcript'].values[0]\n",
    "\n",
    "    itr.set_description(desc=f\"Grammar correction for {ttl}: \")\n",
    "\n",
    "    # Generate embeddings with UNprocessed transcript\n",
    "    doc_emb_unproc, word_emb_unproc = kw_model.extract_embeddings(text, keyphrase_ngram_range=(1, 6), stop_words=None)\n",
    "    pe.loc[pe['title'] == ttl, 'doc_emb_unproc'] = str(list(doc_emb_unproc.squeeze()))\n",
    "\n",
    "    # Grammar correction\n",
    "    input_ids = tokenizer(\"Please correct the grammar & syntax of the following text\" + str(text), max_length=len(text), truncation=True, return_tensors=\"pt\").input_ids.cuda()\n",
    "    outputs = grammar_model.generate(input_ids, max_length=len(text))\n",
    "    edited_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Save transcript as well as original text in 2 separate files\n",
    "    with open(TO + ttl + \"_orig.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    with open(TO + ttl + \"_cleaned.txt\", \"w\") as f:\n",
    "        f.write(edited_text)\n",
    "\n",
    "    itr.set_description(desc=f\"Preprocessing {ttl}: \")\n",
    "    # Usual NLP preprocessing\n",
    "    text_nlp = preprocess_text(edited_text)\n",
    "\n",
    "    # Save preprocessed text\n",
    "    with open(TO + ttl + \"_cleaned_nlp.txt\", \"w\") as f:\n",
    "        f.write(text_nlp)\n",
    "\n",
    "    itr.set_description(desc=f\"Generating embeddings for {ttl}: \")\n",
    "    # Generate embeddings with processed transcript\n",
    "    doc_emb, word_emb = kw_model.extract_embeddings(text_nlp, keyphrase_ngram_range=(1, 6), stop_words=None)\n",
    "    pe.loc[pe['title'] == ttl, 'doc_emb'] = str(list(doc_emb.squeeze()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pre_embed_vec</th>\n",
       "      <th>doc_emb_unproc</th>\n",
       "      <th>doc_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-D Gel Electrophoresis</td>\n",
       "      <td>[-0.19126136814513778, 0.13733942668046725, -0...</td>\n",
       "      <td>[0.24289848, -0.45071986, 1.1598305, 0.4752130...</td>\n",
       "      <td>[0.27433813, -0.51973844, 1.067887, 0.40132207...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 R of Management</td>\n",
       "      <td>[-0.16999237728515493, 0.06898725536530119, 0....</td>\n",
       "      <td>[0.40318987, -0.47663635, 1.0908582, 0.3861287...</td>\n",
       "      <td>[0.45690998, -0.59301126, 1.0201745, 0.2898596...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5R s of Management</td>\n",
       "      <td>[-0.1642900425680676, 0.05772429490165987, 0.0...</td>\n",
       "      <td>[0.43877366, -0.4371265, 1.09398, 0.40499687, ...</td>\n",
       "      <td>[0.4427606, -0.5024001, 1.0034235, 0.2949309, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Absorption of Water by the Soil</td>\n",
       "      <td>[-0.16203413847803913, -0.04227356757548518, -...</td>\n",
       "      <td>[0.32079756, -0.48280507, 1.16238, 0.39818862,...</td>\n",
       "      <td>[0.70309246, -0.694826, 1.1850696, 0.39960852,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acceleration</td>\n",
       "      <td>[-0.1223012690576073, 0.03342131371255797, -0....</td>\n",
       "      <td>[0.30854106, -0.694411, 0.86721295, 0.4675479,...</td>\n",
       "      <td>[0.17490087, -0.32100463, 0.8312924, 0.3257601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>movement by cilia and flagella</td>\n",
       "      <td>[-0.137220452074245, 0.07921627140121146, -0.0...</td>\n",
       "      <td>[0.26817966, -0.43313804, 1.0973607, 0.3645128...</td>\n",
       "      <td>[0.32050088, -0.5102894, 1.0391995, 0.3232281,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>polymerisation</td>\n",
       "      <td>[-0.16961626438499486, -0.021925985188381163, ...</td>\n",
       "      <td>[0.34239438, -0.50310206, 1.0814409, 0.2538067...</td>\n",
       "      <td>[0.2860881, -0.53453565, 0.9084051, 0.25165945...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>protein structure and folding</td>\n",
       "      <td>[-0.16562660838023435, -0.1728222006648213, -0...</td>\n",
       "      <td>[0.32868332, -0.37179884, 1.1365671, 0.4342724...</td>\n",
       "      <td>[0.38396522, -0.46210217, 1.0276499, 0.3523318...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>sieving</td>\n",
       "      <td>[-0.22382595983772374, 0.11274248544353116, 0....</td>\n",
       "      <td>[0.2377191, -0.6006751, 0.91552424, 0.33194014...</td>\n",
       "      <td>[0.07291744, -0.53669393, 0.9200764, 0.271548,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>work</td>\n",
       "      <td>[-0.14311114745678413, -0.040200272919339, -0....</td>\n",
       "      <td>[0.33240938, -0.54079133, 1.0942813, 0.4246311...</td>\n",
       "      <td>[0.38158184, -0.71395755, 0.90818304, 0.376265...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0             2-D Gel Electrophoresis   \n",
       "1                   3 R of Management   \n",
       "2                  5R s of Management   \n",
       "3     Absorption of Water by the Soil   \n",
       "4                        Acceleration   \n",
       "...                               ...   \n",
       "1087   movement by cilia and flagella   \n",
       "1088                   polymerisation   \n",
       "1089    protein structure and folding   \n",
       "1090                          sieving   \n",
       "1091                             work   \n",
       "\n",
       "                                          pre_embed_vec  \\\n",
       "0     [-0.19126136814513778, 0.13733942668046725, -0...   \n",
       "1     [-0.16999237728515493, 0.06898725536530119, 0....   \n",
       "2     [-0.1642900425680676, 0.05772429490165987, 0.0...   \n",
       "3     [-0.16203413847803913, -0.04227356757548518, -...   \n",
       "4     [-0.1223012690576073, 0.03342131371255797, -0....   \n",
       "...                                                 ...   \n",
       "1087  [-0.137220452074245, 0.07921627140121146, -0.0...   \n",
       "1088  [-0.16961626438499486, -0.021925985188381163, ...   \n",
       "1089  [-0.16562660838023435, -0.1728222006648213, -0...   \n",
       "1090  [-0.22382595983772374, 0.11274248544353116, 0....   \n",
       "1091  [-0.14311114745678413, -0.040200272919339, -0....   \n",
       "\n",
       "                                         doc_emb_unproc  \\\n",
       "0     [0.24289848, -0.45071986, 1.1598305, 0.4752130...   \n",
       "1     [0.40318987, -0.47663635, 1.0908582, 0.3861287...   \n",
       "2     [0.43877366, -0.4371265, 1.09398, 0.40499687, ...   \n",
       "3     [0.32079756, -0.48280507, 1.16238, 0.39818862,...   \n",
       "4     [0.30854106, -0.694411, 0.86721295, 0.4675479,...   \n",
       "...                                                 ...   \n",
       "1087  [0.26817966, -0.43313804, 1.0973607, 0.3645128...   \n",
       "1088  [0.34239438, -0.50310206, 1.0814409, 0.2538067...   \n",
       "1089  [0.32868332, -0.37179884, 1.1365671, 0.4342724...   \n",
       "1090  [0.2377191, -0.6006751, 0.91552424, 0.33194014...   \n",
       "1091  [0.33240938, -0.54079133, 1.0942813, 0.4246311...   \n",
       "\n",
       "                                                doc_emb  \n",
       "0     [0.27433813, -0.51973844, 1.067887, 0.40132207...  \n",
       "1     [0.45690998, -0.59301126, 1.0201745, 0.2898596...  \n",
       "2     [0.4427606, -0.5024001, 1.0034235, 0.2949309, ...  \n",
       "3     [0.70309246, -0.694826, 1.1850696, 0.39960852,...  \n",
       "4     [0.17490087, -0.32100463, 0.8312924, 0.3257601...  \n",
       "...                                                 ...  \n",
       "1087  [0.32050088, -0.5102894, 1.0391995, 0.3232281,...  \n",
       "1088  [0.2860881, -0.53453565, 0.9084051, 0.25165945...  \n",
       "1089  [0.38396522, -0.46210217, 1.0276499, 0.3523318...  \n",
       "1090  [0.07291744, -0.53669393, 0.9200764, 0.271548,...  \n",
       "1091  [0.38158184, -0.71395755, 0.90818304, 0.376265...  \n",
       "\n",
       "[1092 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults for the 2 no-transcript videos\n",
    "pe.loc[pe['title'] == \"3D circulatory system\", 'doc_emb'] = str([0]*768)\n",
    "pe.loc[pe['title'] == \"3D circulatory system\", 'doc_emb_unproc'] = str([0]*768)\n",
    "pe.loc[pe['title'] == \"Introduction to Human Musculo - Skeletal System\", 'doc_emb'] = str([0]*768)\n",
    "pe.loc[pe['title'] == \"Introduction to Human Musculo - Skeletal System\", 'doc_emb_unproc'] = str([0]*768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to disk\n",
    "# pe.to_csv(\"../data/kagdata/emb_std_combined.csv\", index=False) # NOTE: Careful about overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reqv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
